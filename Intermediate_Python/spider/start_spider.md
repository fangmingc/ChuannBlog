## 爬虫基础

### 爬虫原理
本质：模拟浏览器向服务器发送请求获取数据。

- 爬虫的比喻
	- 如果我们把互联网比作一张大的蜘蛛网，那一台计算机上的数据便是蜘蛛网上的一个猎物，而爬虫程序就是一只小蜘蛛，沿着蜘蛛网抓取自己想要的猎物/数据
- 爬虫的定义
	- 向网站发起请求，获取资源后分析并提取有用数据的程序 
- 爬虫的价值
	- 互联网中最有价值的便是数据，比如天猫商城的商品信息，链家网的租房信息，雪球网的证券投资信息等等，这些数据都代表了各个行业的真金白银，可以说，谁掌握了行业内的第一手数据，谁就成了整个行业的主宰，如果把整个互联网的数据比喻为一座宝藏，那我们的爬虫课程就是来教大家如何来高效地挖掘这些宝藏，掌握了爬虫技能，你就成了所有互联网信息公司幕后的老板，换言之，它们都在免费为你提供有价值的数据。

### 爬虫的基本流程
1. 发送请求
	- 
2. 获取响应内容
3. 解析内容
4. 保存数据

### 请求和响应
#### 请求request
以访问http://www.baidu.com为例
- 请求url
	- http://www.baidu.com
- 请求方法：
	- GET
- 请求头
	- 重要：
		- cookie
		- 用户代理
			- 请求者的身份
		- referer
			- 从何处跳转至本页面
	- 次要：
		- 请求的数据类型
		- 请求的数据编码
		- 请求的数据语言
		- 连接状态
		- 请求的域名
- 请求体

#### 响应
以访问http://www.baidu.com为例
- 响应的状态码
	- 200成功
	- 302重定向
- 响应体
	- html
	- json
	- 二进制


### 爬虫小结
1. 总结爬虫流程：
	- 爬取--->解析--->存储
2. 爬虫所需工具：
	- 请求库：requests,selenium
	- 解析库：正则，beautifulsoup，pyquery
	- 存储库：文件，MySQL，Mongodb，Redis
3. 爬虫常用框架
	- scrapy
4. 爬虫的实现其次，主要是要学会分析爬取的目标网站
	- 站点通过何种方式辨识用户?
	- 获取站点的数据需要哪些步骤？
	- 根据步骤制定爬虫方案

